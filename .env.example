RUNNER_IMAGE=adastravideo/transcription:latest
AI_RUNNER_PORT=8000
HF_TOKEN=token
#vllm local summary settings
#model options (generally 4B or less for local GPU inference)
LOCAL_SUMMARY_MODEL=Nanbeige/Nanbeige4-3B-Thinking-2511
MAX_CONCURRENT_SUMMARIES=10
CUDA_VISIBLE_DEVICES=0
#stream processing pipeline image
AI_RUNNER_URL=http://byoc-stream-runner:8000
CAPABILITY_NAME=audio-transcription
CAPABILITY_CAPACITY=1
CAPABILITY_PRICE_PER_UNIT=1002
CAPABILITY_PRICE_SCALING=1
CAPABILITY_PRICE_CURRENCY=WEI
ORCH_SERVICE_ADDR=byoc-stream-orchestrator:9995
ORCH_SECRET=orch-secret
#Not using runner proxy (ai-runner is local to Orchestrator)
#if using runner-proxy service (dns name for the runner)
#HOST=[dns name]
#AI_RUNNER_URL=https://[ip or dns name]:9099/ai-runner/api
#AI_RUNNER_PORT=9099
#AI_RUNNER_HTTPS_EMAIL=[email for https certs, only needed if want not self-signed certs]
